---
layout: archive
title: ""
permalink: /publications/
author_profile: true
---

# Publications

* **Sequential Large Language Model-Based Hyper-parameter Optimization (SLLMBO)**  
**Kanan Mahammadli**, Seyda Ertekin  
*Preprint on arXiv (2024)*  
[View on arXiv](https://arxiv.org/abs/2410.20302)  
Developed the SLLMBO framework to enhance hyperparameter optimization using large language models (LLMs). The framework incorporates a hybrid LLM-Tree Structured Parzen Estimator (LLM-TPE) sampler, reducing API costs, mitigating overexploitation, and automating the tuning process. Currently being finalized for submission to the *Journal of Machine Learning Research*.
